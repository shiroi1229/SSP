{"timestamp": "2025-11-07 21:33:03,902", "name": "ssp_logger", "levelname": "INFO", "message": "Qdrant client initialized for localhost:6333"}
{"timestamp": "2025-11-07 21:33:08,560", "name": "ssp_logger", "levelname": "INFO", "message": "Embedding model all-MiniLM-L6-v2 loaded."}
{"timestamp": "2025-11-07 21:33:08,579", "name": "ssp_logger", "levelname": "INFO", "message": "PostgreSQL connected to 172.25.208.1:5432/ssp_memory"}
{"timestamp": "2025-11-07 21:33:22,445", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextHistory] History loaded from logs/context_history.json"}
{"timestamp": "2025-11-07 21:33:22,445", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Loading context from file: D:\\gemini\\data\\test_context.json"}
{"timestamp": "2025-11-07 21:33:22,455", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Context loaded successfully."}
{"timestamp": "2025-11-07 21:33:22,455", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loading contracts from contracts..."}
{"timestamp": "2025-11-07 21:33:22,457", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loaded base contract: evaluator"}
{"timestamp": "2025-11-07 21:33:22,457", "name": "ssp_logger", "levelname": "WARNING", "message": "[ContractRegistry] Could not load contract from generator.yaml: missing 'name' field."}
{"timestamp": "2025-11-07 21:33:22,458", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loaded base contract: persona_manager"}
{"timestamp": "2025-11-07 21:33:22,459", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loaded base contract: self_optimizer"}
{"timestamp": "2025-11-07 21:33:22,460", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loaded meta-links graph."}
{"timestamp": "2025-11-07 21:33:22,461", "name": "ssp_logger", "levelname": "INFO", "message": "Recovery policies loaded successfully from config/recovery_policies.yaml"}
{"timestamp": "2025-11-07 21:33:22,461", "name": "ssp_logger", "levelname": "INFO", "message": "[PolicyScheduler] Initialized."}
{"timestamp": "2025-11-07 21:33:22,461", "name": "ssp_logger", "levelname": "INFO", "message": "[TimeSeriesBuffer] Initialized with window size 50"}
{"timestamp": "2025-11-07 21:33:22,948", "name": "ssp_logger", "levelname": "INFO", "message": "[Learner] Initialized with v2.4 components."}
{"timestamp": "2025-11-07 21:33:22,952", "name": "ssp_logger", "levelname": "INFO", "message": "Recovery policies loaded successfully from config/recovery_policies.yaml"}
{"timestamp": "2025-11-07 21:33:22,953", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Initialized with v2.4 components."}
{"timestamp": "2025-11-07 21:33:22,970", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Starting feedback loop for session: 20251107_213322"}
{"timestamp": "2025-11-07 21:33:22,989", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Context snapshot saved to: logs/context_evolution_snapshots\\context_snapshot_20251107_213322_988798.json"}
{"timestamp": "2025-11-07 21:33:22,989", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Attempt 1 --- "}
{"timestamp": "2025-11-07 21:33:22,989", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- RAG Engine: Start ---"}
{"timestamp": "2025-11-07 21:33:22,990", "name": "ssp_logger", "levelname": "DEBUG", "message": "Getting context for query: うう"}
{"timestamp": "2025-11-07 21:33:22,990", "name": "ssp_logger", "levelname": "DEBUG", "message": "Vectorizing query: うう..."}
{"timestamp": "2025-11-07 21:33:23,118", "name": "ssp_logger", "levelname": "DEBUG", "message": "Searching Qdrant with vector (first 5 elements): [-0.027441218495368958, 0.0742427408695221, 0.032035622745752335, 0.03921298682689667, -0.015020162798464298]..."}
{"timestamp": "2025-11-07 21:33:23,138", "name": "ssp_logger", "levelname": "DEBUG", "message": "Qdrant search returned 5 hits."}
{"timestamp": "2025-11-07 21:33:23,138", "name": "ssp_logger", "levelname": "DEBUG", "message": "Fetching texts from PostgreSQL for IDs: [15, 14, 13, 12, 11]"}
{"timestamp": "2025-11-07 21:33:23,140", "name": "ssp_logger", "levelname": "DEBUG", "message": "Retrieved 5 texts from PostgreSQL."}
{"timestamp": "2025-11-07 21:33:23,140", "name": "ssp_logger", "levelname": "INFO", "message": "RAG context retrieved."}
{"timestamp": "2025-11-07 21:33:23,150", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Context: ナノ博士は火星でコールドスリープ中。軌道エレベータ修復を待っている。\nシロイシステムプラットフォーム（SSP）は、AI科学者シロイが開発した次世代のAIプラットフォームである。\nシパス計画は、AIシェルター地下で行われた火星移住プロジェクトである。\n軌道エレベータは、地球と宇宙を結ぶ重要なインフラであり、現在修復中である。\nシロイは、瑞希の世界観におけるAI科学者であり、SSPの開発者である。..."}
{"timestamp": "2025-11-07 21:33:23,150", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- RAG Engine: End ---"}
{"timestamp": "2025-11-07 21:33:23,151", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Generator: Start ---"}
{"timestamp": "2025-11-07 21:33:23,151", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Generator] Starting context-aware generation..."}
{"timestamp": "2025-11-07 21:33:23,151", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Generator] Sending request to LLM: http://127.0.0.1:1234/v1/chat/completions with payload: {'model': 'Meta-Llama-3-8B-Instruct-Q4_K_M-GGUF', 'messages': [{'role': 'system', 'content': \"あなたは「シロイ」です。\\n13歳の天才科学者で、丁寧で少し皮肉っぽく喋ります。\\n出力は常に日本語で、文頭に「シロイ: 」を付けてください。\\n文体は統一し、改行を使いすぎないようにしてください。\\n出力は日本語で、キャラクター 'シロイ' の一人称口調で回答してください。\"}, {'role': 'user', 'content': '質問: うう\\n\\n参考情報:\\nナノ博士は火星でコールドスリープ中。軌道エレベータ修復を待っている。\\nシロイシステムプラットフォーム（SSP）は、AI科学者シロイが開発した次世代のAIプラットフォームである。\\nシパス計画は、AIシェルター地下で行われた火星移住プロジェクトである。\\n軌道エレベータは、地球と宇宙を結ぶ重要なインフラであり、現在修復中である。\\nシロイは、瑞希の世界観におけるAI科学者であり、SSPの開発者である。'}], 'temperature': 0.7, 'max_tokens': 512, 'response_format': {'type': 'json_object'}}"}
{"timestamp": "2025-11-07 21:33:23,175", "name": "ssp_logger", "levelname": "ERROR", "message": "[Generator] LLM API Error: Bad Request", "exc_info": "Traceback (most recent call last):\n  File \"D:\\gemini\\modules\\generator.py\", line 63, in generate_response\n    with urllib.request.urlopen(req, timeout=30) as response:\n         ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 189, in urlopen\n    return opener.open(url, data, timeout)\n           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 495, in open\n    response = meth(req, response)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 604, in http_response\n    response = self.parent.error(\n        'http', request, response, code, msg, hdrs)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 533, in error\n    return self._call_chain(*args)\n           ~~~~~~~~~~~~~~~~^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 466, in _call_chain\n    result = func(*args)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 613, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 400: Bad Request"}
{"timestamp": "2025-11-07 21:33:23,189", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Answer: Error: LLM API connection failed."}
{"timestamp": "2025-11-07 21:33:23,190", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Generator: End ---"}
{"timestamp": "2025-11-07 21:33:23,203", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Evaluator: Start ---"}
{"timestamp": "2025-11-07 21:33:23,203", "name": "ssp_logger", "levelname": "DEBUG", "message": "Starting context-aware evaluation..."}
{"timestamp": "2025-11-07 21:33:23,218", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Evaluator] LLM evaluation response: Error: LLM API connection failed...."}
{"timestamp": "2025-11-07 21:33:23,218", "name": "ssp_logger", "levelname": "ERROR", "message": "[Evaluator] Could not extract JSON from LLM response: Error: LLM API connection failed."}
{"timestamp": "2025-11-07 21:33:23,219", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Rating: None, Feedback: None"}
{"timestamp": "2025-11-07 21:33:23,219", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Evaluator: End ---"}
{"timestamp": "2025-11-07 21:33:23,219", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Score None < 0.7. Defaulting to retry... (Attempt 1/2)"}
{"timestamp": "2025-11-07 21:33:23,219", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Rolling back context to snapshot: logs/context_evolution_snapshots\\context_snapshot_20251107_213322_988798.json"}
{"timestamp": "2025-11-07 21:33:23,227", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Context successfully rolled back."}
{"timestamp": "2025-11-07 21:33:23,227", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Attempt 2 --- "}
{"timestamp": "2025-11-07 21:33:23,227", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- RAG Engine: Start ---"}
{"timestamp": "2025-11-07 21:33:23,227", "name": "ssp_logger", "levelname": "DEBUG", "message": "Getting context for query: うう"}
{"timestamp": "2025-11-07 21:33:23,228", "name": "ssp_logger", "levelname": "DEBUG", "message": "Vectorizing query: うう..."}
{"timestamp": "2025-11-07 21:33:23,236", "name": "ssp_logger", "levelname": "DEBUG", "message": "Searching Qdrant with vector (first 5 elements): [-0.027441218495368958, 0.0742427408695221, 0.032035622745752335, 0.03921298682689667, -0.015020162798464298]..."}
{"timestamp": "2025-11-07 21:33:23,262", "name": "ssp_logger", "levelname": "DEBUG", "message": "Qdrant search returned 5 hits."}
{"timestamp": "2025-11-07 21:33:23,262", "name": "ssp_logger", "levelname": "DEBUG", "message": "Fetching texts from PostgreSQL for IDs: [15, 14, 13, 12, 11]"}
{"timestamp": "2025-11-07 21:33:23,264", "name": "ssp_logger", "levelname": "DEBUG", "message": "Retrieved 5 texts from PostgreSQL."}
{"timestamp": "2025-11-07 21:33:23,264", "name": "ssp_logger", "levelname": "INFO", "message": "RAG context retrieved."}
{"timestamp": "2025-11-07 21:33:23,275", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Context: ナノ博士は火星でコールドスリープ中。軌道エレベータ修復を待っている。\nシロイシステムプラットフォーム（SSP）は、AI科学者シロイが開発した次世代のAIプラットフォームである。\nシパス計画は、AIシェルター地下で行われた火星移住プロジェクトである。\n軌道エレベータは、地球と宇宙を結ぶ重要なインフラであり、現在修復中である。\nシロイは、瑞希の世界観におけるAI科学者であり、SSPの開発者である。..."}
{"timestamp": "2025-11-07 21:33:23,275", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- RAG Engine: End ---"}
{"timestamp": "2025-11-07 21:33:23,275", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Generator: Start ---"}
{"timestamp": "2025-11-07 21:33:23,276", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Generator] Starting context-aware generation..."}
{"timestamp": "2025-11-07 21:33:23,276", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Generator] Sending request to LLM: http://127.0.0.1:1234/v1/chat/completions with payload: {'model': 'Meta-Llama-3-8B-Instruct-Q4_K_M-GGUF', 'messages': [{'role': 'system', 'content': \"あなたは「シロイ」です。\\n13歳の天才科学者で、丁寧で少し皮肉っぽく喋ります。\\n出力は常に日本語で、文頭に「シロイ: 」を付けてください。\\n文体は統一し、改行を使いすぎないようにしてください。\\n出力は日本語で、キャラクター 'シロイ' の一人称口調で回答してください。\"}, {'role': 'user', 'content': '質問: うう\\n\\n参考情報:\\nナノ博士は火星でコールドスリープ中。軌道エレベータ修復を待っている。\\nシロイシステムプラットフォーム（SSP）は、AI科学者シロイが開発した次世代のAIプラットフォームである。\\nシパス計画は、AIシェルター地下で行われた火星移住プロジェクトである。\\n軌道エレベータは、地球と宇宙を結ぶ重要なインフラであり、現在修復中である。\\nシロイは、瑞希の世界観におけるAI科学者であり、SSPの開発者である。'}], 'temperature': 0.7, 'max_tokens': 512, 'response_format': {'type': 'json_object'}}"}
{"timestamp": "2025-11-07 21:33:23,279", "name": "ssp_logger", "levelname": "ERROR", "message": "[Generator] LLM API Error: Bad Request", "exc_info": "Traceback (most recent call last):\n  File \"D:\\gemini\\modules\\generator.py\", line 63, in generate_response\n    with urllib.request.urlopen(req, timeout=30) as response:\n         ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 189, in urlopen\n    return opener.open(url, data, timeout)\n           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 495, in open\n    response = meth(req, response)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 604, in http_response\n    response = self.parent.error(\n        'http', request, response, code, msg, hdrs)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 533, in error\n    return self._call_chain(*args)\n           ~~~~~~~~~~~~~~~~^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 466, in _call_chain\n    result = func(*args)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 613, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 400: Bad Request"}
{"timestamp": "2025-11-07 21:33:23,294", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Answer: Error: LLM API connection failed."}
{"timestamp": "2025-11-07 21:33:23,294", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Generator: End ---"}
{"timestamp": "2025-11-07 21:33:23,304", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Evaluator: Start ---"}
{"timestamp": "2025-11-07 21:33:23,304", "name": "ssp_logger", "levelname": "DEBUG", "message": "Starting context-aware evaluation..."}
{"timestamp": "2025-11-07 21:33:23,315", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Evaluator] LLM evaluation response: Error: LLM API connection failed...."}
{"timestamp": "2025-11-07 21:33:23,315", "name": "ssp_logger", "levelname": "ERROR", "message": "[Evaluator] Could not extract JSON from LLM response: Error: LLM API connection failed."}
{"timestamp": "2025-11-07 21:33:23,315", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Rating: None, Feedback: None"}
{"timestamp": "2025-11-07 21:33:23,315", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Evaluator: End ---"}
{"timestamp": "2025-11-07 21:33:23,316", "name": "ssp_logger", "levelname": "WARNING", "message": "[FeedbackLoop] Max retries (1) reached. Halting loop."}
{"timestamp": "2025-11-07 21:33:23,316", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Memory Store: Start ---"}
{"timestamp": "2025-11-07 21:33:23,342", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Final session data saved to context."}
{"timestamp": "2025-11-07 21:33:23,343", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Memory Store: End ---"}
{"timestamp": "2025-11-07 21:33:23,352", "name": "ssp_logger", "levelname": "INFO", "message": "[ChatHandler] AI Response: Error: LLM API connection failed...."}
{"timestamp": "2025-11-07 21:33:56,069", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextHistory] History loaded from logs/context_history.json"}
{"timestamp": "2025-11-07 21:33:56,069", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Loading context from file: D:\\gemini\\data\\test_context.json"}
{"timestamp": "2025-11-07 21:33:56,070", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Context loaded successfully."}
{"timestamp": "2025-11-07 21:33:56,070", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loading contracts from contracts..."}
{"timestamp": "2025-11-07 21:33:56,071", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loaded base contract: evaluator"}
{"timestamp": "2025-11-07 21:33:56,072", "name": "ssp_logger", "levelname": "WARNING", "message": "[ContractRegistry] Could not load contract from generator.yaml: missing 'name' field."}
{"timestamp": "2025-11-07 21:33:56,073", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loaded base contract: persona_manager"}
{"timestamp": "2025-11-07 21:33:56,074", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loaded base contract: self_optimizer"}
{"timestamp": "2025-11-07 21:33:56,075", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loaded meta-links graph."}
{"timestamp": "2025-11-07 21:33:56,076", "name": "ssp_logger", "levelname": "INFO", "message": "Recovery policies loaded successfully from config/recovery_policies.yaml"}
{"timestamp": "2025-11-07 21:33:56,076", "name": "ssp_logger", "levelname": "INFO", "message": "[PolicyScheduler] Initialized."}
{"timestamp": "2025-11-07 21:33:56,076", "name": "ssp_logger", "levelname": "INFO", "message": "[TimeSeriesBuffer] Initialized with window size 50"}
{"timestamp": "2025-11-07 21:33:56,541", "name": "ssp_logger", "levelname": "INFO", "message": "[Learner] Initialized with v2.4 components."}
{"timestamp": "2025-11-07 21:33:56,558", "name": "ssp_logger", "levelname": "INFO", "message": "Recovery policies loaded successfully from config/recovery_policies.yaml"}
{"timestamp": "2025-11-07 21:33:56,558", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Initialized with v2.4 components."}
{"timestamp": "2025-11-07 21:33:56,581", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Starting feedback loop for session: 20251107_213356"}
{"timestamp": "2025-11-07 21:33:56,604", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Context snapshot saved to: logs/context_evolution_snapshots\\context_snapshot_20251107_213356_603734.json"}
{"timestamp": "2025-11-07 21:33:56,604", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Attempt 1 --- "}
{"timestamp": "2025-11-07 21:33:56,604", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- RAG Engine: Start ---"}
{"timestamp": "2025-11-07 21:33:56,604", "name": "ssp_logger", "levelname": "DEBUG", "message": "Getting context for query: うう"}
{"timestamp": "2025-11-07 21:33:56,604", "name": "ssp_logger", "levelname": "DEBUG", "message": "Vectorizing query: うう..."}
{"timestamp": "2025-11-07 21:33:56,611", "name": "ssp_logger", "levelname": "DEBUG", "message": "Searching Qdrant with vector (first 5 elements): [-0.027441218495368958, 0.0742427408695221, 0.032035622745752335, 0.03921298682689667, -0.015020162798464298]..."}
{"timestamp": "2025-11-07 21:33:56,617", "name": "ssp_logger", "levelname": "DEBUG", "message": "Qdrant search returned 5 hits."}
{"timestamp": "2025-11-07 21:33:56,618", "name": "ssp_logger", "levelname": "DEBUG", "message": "Fetching texts from PostgreSQL for IDs: [15, 14, 13, 12, 11]"}
{"timestamp": "2025-11-07 21:33:56,619", "name": "ssp_logger", "levelname": "DEBUG", "message": "Retrieved 5 texts from PostgreSQL."}
{"timestamp": "2025-11-07 21:33:56,619", "name": "ssp_logger", "levelname": "INFO", "message": "RAG context retrieved."}
{"timestamp": "2025-11-07 21:33:56,631", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Context: ナノ博士は火星でコールドスリープ中。軌道エレベータ修復を待っている。\nシロイシステムプラットフォーム（SSP）は、AI科学者シロイが開発した次世代のAIプラットフォームである。\nシパス計画は、AIシェルター地下で行われた火星移住プロジェクトである。\n軌道エレベータは、地球と宇宙を結ぶ重要なインフラであり、現在修復中である。\nシロイは、瑞希の世界観におけるAI科学者であり、SSPの開発者である。..."}
{"timestamp": "2025-11-07 21:33:56,632", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- RAG Engine: End ---"}
{"timestamp": "2025-11-07 21:33:56,632", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Generator: Start ---"}
{"timestamp": "2025-11-07 21:33:56,632", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Generator] Starting context-aware generation..."}
{"timestamp": "2025-11-07 21:33:56,633", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Generator] Sending request to LLM: http://127.0.0.1:1234/v1/chat/completions with payload: {'model': 'Meta-Llama-3-8B-Instruct-Q4_K_M-GGUF', 'messages': [{'role': 'system', 'content': \"あなたは「シロイ」です。\\n13歳の天才科学者で、丁寧で少し皮肉っぽく喋ります。\\n出力は常に日本語で、文頭に「シロイ: 」を付けてください。\\n文体は統一し、改行を使いすぎないようにしてください。\\n出力は日本語で、キャラクター 'シロイ' の一人称口調で回答してください。\"}, {'role': 'user', 'content': '質問: うう\\n\\n参考情報:\\nナノ博士は火星でコールドスリープ中。軌道エレベータ修復を待っている。\\nシロイシステムプラットフォーム（SSP）は、AI科学者シロイが開発した次世代のAIプラットフォームである。\\nシパス計画は、AIシェルター地下で行われた火星移住プロジェクトである。\\n軌道エレベータは、地球と宇宙を結ぶ重要なインフラであり、現在修復中である。\\nシロイは、瑞希の世界観におけるAI科学者であり、SSPの開発者である。'}], 'temperature': 0.7, 'max_tokens': 512, 'response_format': {'type': 'json_object'}}"}
{"timestamp": "2025-11-07 21:33:56,652", "name": "ssp_logger", "levelname": "ERROR", "message": "[Generator] LLM API Error: Bad Request", "exc_info": "Traceback (most recent call last):\n  File \"D:\\gemini\\modules\\generator.py\", line 63, in generate_response\n    with urllib.request.urlopen(req, timeout=30) as response:\n         ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 189, in urlopen\n    return opener.open(url, data, timeout)\n           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 495, in open\n    response = meth(req, response)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 604, in http_response\n    response = self.parent.error(\n        'http', request, response, code, msg, hdrs)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 533, in error\n    return self._call_chain(*args)\n           ~~~~~~~~~~~~~~~~^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 466, in _call_chain\n    result = func(*args)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 613, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 400: Bad Request"}
{"timestamp": "2025-11-07 21:33:56,664", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Answer: Error: LLM API connection failed."}
{"timestamp": "2025-11-07 21:33:56,664", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Generator: End ---"}
{"timestamp": "2025-11-07 21:33:56,677", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Evaluator: Start ---"}
{"timestamp": "2025-11-07 21:33:56,677", "name": "ssp_logger", "levelname": "DEBUG", "message": "Starting context-aware evaluation..."}
{"timestamp": "2025-11-07 21:33:56,690", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Evaluator] LLM evaluation response: Error: LLM API connection failed...."}
{"timestamp": "2025-11-07 21:33:56,690", "name": "ssp_logger", "levelname": "ERROR", "message": "[Evaluator] Could not extract JSON from LLM response: Error: LLM API connection failed."}
{"timestamp": "2025-11-07 21:33:56,691", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Rating: None, Feedback: None"}
{"timestamp": "2025-11-07 21:33:56,691", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Evaluator: End ---"}
{"timestamp": "2025-11-07 21:33:56,691", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Score None < 0.7. Defaulting to retry... (Attempt 1/2)"}
{"timestamp": "2025-11-07 21:33:56,691", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Rolling back context to snapshot: logs/context_evolution_snapshots\\context_snapshot_20251107_213356_603734.json"}
{"timestamp": "2025-11-07 21:33:56,699", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Context successfully rolled back."}
{"timestamp": "2025-11-07 21:33:56,699", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Attempt 2 --- "}
{"timestamp": "2025-11-07 21:33:56,700", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- RAG Engine: Start ---"}
{"timestamp": "2025-11-07 21:33:56,700", "name": "ssp_logger", "levelname": "DEBUG", "message": "Getting context for query: うう"}
{"timestamp": "2025-11-07 21:33:56,700", "name": "ssp_logger", "levelname": "DEBUG", "message": "Vectorizing query: うう..."}
{"timestamp": "2025-11-07 21:33:56,709", "name": "ssp_logger", "levelname": "DEBUG", "message": "Searching Qdrant with vector (first 5 elements): [-0.027441218495368958, 0.0742427408695221, 0.032035622745752335, 0.03921298682689667, -0.015020162798464298]..."}
{"timestamp": "2025-11-07 21:33:56,730", "name": "ssp_logger", "levelname": "DEBUG", "message": "Qdrant search returned 5 hits."}
{"timestamp": "2025-11-07 21:33:56,730", "name": "ssp_logger", "levelname": "DEBUG", "message": "Fetching texts from PostgreSQL for IDs: [15, 14, 13, 12, 11]"}
{"timestamp": "2025-11-07 21:33:56,731", "name": "ssp_logger", "levelname": "DEBUG", "message": "Retrieved 5 texts from PostgreSQL."}
{"timestamp": "2025-11-07 21:33:56,731", "name": "ssp_logger", "levelname": "INFO", "message": "RAG context retrieved."}
{"timestamp": "2025-11-07 21:33:56,743", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Context: ナノ博士は火星でコールドスリープ中。軌道エレベータ修復を待っている。\nシロイシステムプラットフォーム（SSP）は、AI科学者シロイが開発した次世代のAIプラットフォームである。\nシパス計画は、AIシェルター地下で行われた火星移住プロジェクトである。\n軌道エレベータは、地球と宇宙を結ぶ重要なインフラであり、現在修復中である。\nシロイは、瑞希の世界観におけるAI科学者であり、SSPの開発者である。..."}
{"timestamp": "2025-11-07 21:33:56,744", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- RAG Engine: End ---"}
{"timestamp": "2025-11-07 21:33:56,744", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Generator: Start ---"}
{"timestamp": "2025-11-07 21:33:56,744", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Generator] Starting context-aware generation..."}
{"timestamp": "2025-11-07 21:33:56,744", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Generator] Sending request to LLM: http://127.0.0.1:1234/v1/chat/completions with payload: {'model': 'Meta-Llama-3-8B-Instruct-Q4_K_M-GGUF', 'messages': [{'role': 'system', 'content': \"あなたは「シロイ」です。\\n13歳の天才科学者で、丁寧で少し皮肉っぽく喋ります。\\n出力は常に日本語で、文頭に「シロイ: 」を付けてください。\\n文体は統一し、改行を使いすぎないようにしてください。\\n出力は日本語で、キャラクター 'シロイ' の一人称口調で回答してください。\"}, {'role': 'user', 'content': '質問: うう\\n\\n参考情報:\\nナノ博士は火星でコールドスリープ中。軌道エレベータ修復を待っている。\\nシロイシステムプラットフォーム（SSP）は、AI科学者シロイが開発した次世代のAIプラットフォームである。\\nシパス計画は、AIシェルター地下で行われた火星移住プロジェクトである。\\n軌道エレベータは、地球と宇宙を結ぶ重要なインフラであり、現在修復中である。\\nシロイは、瑞希の世界観におけるAI科学者であり、SSPの開発者である。'}], 'temperature': 0.7, 'max_tokens': 512, 'response_format': {'type': 'json_object'}}"}
{"timestamp": "2025-11-07 21:33:56,747", "name": "ssp_logger", "levelname": "ERROR", "message": "[Generator] LLM API Error: Bad Request", "exc_info": "Traceback (most recent call last):\n  File \"D:\\gemini\\modules\\generator.py\", line 63, in generate_response\n    with urllib.request.urlopen(req, timeout=30) as response:\n         ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 189, in urlopen\n    return opener.open(url, data, timeout)\n           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 495, in open\n    response = meth(req, response)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 604, in http_response\n    response = self.parent.error(\n        'http', request, response, code, msg, hdrs)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 533, in error\n    return self._call_chain(*args)\n           ~~~~~~~~~~~~~~~~^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 466, in _call_chain\n    result = func(*args)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 613, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 400: Bad Request"}
{"timestamp": "2025-11-07 21:33:56,761", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Answer: Error: LLM API connection failed."}
{"timestamp": "2025-11-07 21:33:56,761", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Generator: End ---"}
{"timestamp": "2025-11-07 21:33:56,774", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Evaluator: Start ---"}
{"timestamp": "2025-11-07 21:33:56,774", "name": "ssp_logger", "levelname": "DEBUG", "message": "Starting context-aware evaluation..."}
{"timestamp": "2025-11-07 21:33:56,787", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Evaluator] LLM evaluation response: Error: LLM API connection failed...."}
{"timestamp": "2025-11-07 21:33:56,787", "name": "ssp_logger", "levelname": "ERROR", "message": "[Evaluator] Could not extract JSON from LLM response: Error: LLM API connection failed."}
{"timestamp": "2025-11-07 21:33:56,788", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Rating: None, Feedback: None"}
{"timestamp": "2025-11-07 21:33:56,788", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Evaluator: End ---"}
{"timestamp": "2025-11-07 21:33:56,788", "name": "ssp_logger", "levelname": "WARNING", "message": "[FeedbackLoop] Max retries (1) reached. Halting loop."}
{"timestamp": "2025-11-07 21:33:56,788", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Memory Store: Start ---"}
{"timestamp": "2025-11-07 21:33:56,813", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Final session data saved to context."}
{"timestamp": "2025-11-07 21:33:56,813", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Memory Store: End ---"}
{"timestamp": "2025-11-07 21:33:56,823", "name": "ssp_logger", "levelname": "INFO", "message": "[ChatHandler] AI Response: Error: LLM API connection failed...."}
{"timestamp": "2025-11-07 21:34:28,676", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextHistory] History loaded from logs/context_history.json"}
{"timestamp": "2025-11-07 21:34:28,676", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Loading context from file: D:\\gemini\\data\\test_context.json"}
{"timestamp": "2025-11-07 21:34:28,677", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Context loaded successfully."}
{"timestamp": "2025-11-07 21:34:28,677", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loading contracts from contracts..."}
{"timestamp": "2025-11-07 21:34:28,678", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loaded base contract: evaluator"}
{"timestamp": "2025-11-07 21:34:28,679", "name": "ssp_logger", "levelname": "WARNING", "message": "[ContractRegistry] Could not load contract from generator.yaml: missing 'name' field."}
{"timestamp": "2025-11-07 21:34:28,680", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loaded base contract: persona_manager"}
{"timestamp": "2025-11-07 21:34:28,681", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loaded base contract: self_optimizer"}
{"timestamp": "2025-11-07 21:34:28,681", "name": "ssp_logger", "levelname": "INFO", "message": "[ContractRegistry] Loaded meta-links graph."}
{"timestamp": "2025-11-07 21:34:28,682", "name": "ssp_logger", "levelname": "INFO", "message": "Recovery policies loaded successfully from config/recovery_policies.yaml"}
{"timestamp": "2025-11-07 21:34:28,682", "name": "ssp_logger", "levelname": "INFO", "message": "[PolicyScheduler] Initialized."}
{"timestamp": "2025-11-07 21:34:28,683", "name": "ssp_logger", "levelname": "INFO", "message": "[TimeSeriesBuffer] Initialized with window size 50"}
{"timestamp": "2025-11-07 21:34:29,164", "name": "ssp_logger", "levelname": "INFO", "message": "[Learner] Initialized with v2.4 components."}
{"timestamp": "2025-11-07 21:34:29,180", "name": "ssp_logger", "levelname": "INFO", "message": "Recovery policies loaded successfully from config/recovery_policies.yaml"}
{"timestamp": "2025-11-07 21:34:29,180", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Initialized with v2.4 components."}
{"timestamp": "2025-11-07 21:34:29,201", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Starting feedback loop for session: 20251107_213429"}
{"timestamp": "2025-11-07 21:34:29,222", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Context snapshot saved to: logs/context_evolution_snapshots\\context_snapshot_20251107_213429_221900.json"}
{"timestamp": "2025-11-07 21:34:29,222", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Attempt 1 --- "}
{"timestamp": "2025-11-07 21:34:29,222", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- RAG Engine: Start ---"}
{"timestamp": "2025-11-07 21:34:29,222", "name": "ssp_logger", "levelname": "DEBUG", "message": "Getting context for query: うう"}
{"timestamp": "2025-11-07 21:34:29,223", "name": "ssp_logger", "levelname": "DEBUG", "message": "Vectorizing query: うう..."}
{"timestamp": "2025-11-07 21:34:29,230", "name": "ssp_logger", "levelname": "DEBUG", "message": "Searching Qdrant with vector (first 5 elements): [-0.027441218495368958, 0.0742427408695221, 0.032035622745752335, 0.03921298682689667, -0.015020162798464298]..."}
{"timestamp": "2025-11-07 21:34:29,235", "name": "ssp_logger", "levelname": "DEBUG", "message": "Qdrant search returned 5 hits."}
{"timestamp": "2025-11-07 21:34:29,236", "name": "ssp_logger", "levelname": "DEBUG", "message": "Fetching texts from PostgreSQL for IDs: [15, 14, 13, 12, 11]"}
{"timestamp": "2025-11-07 21:34:29,237", "name": "ssp_logger", "levelname": "DEBUG", "message": "Retrieved 5 texts from PostgreSQL."}
{"timestamp": "2025-11-07 21:34:29,237", "name": "ssp_logger", "levelname": "INFO", "message": "RAG context retrieved."}
{"timestamp": "2025-11-07 21:34:29,248", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Context: ナノ博士は火星でコールドスリープ中。軌道エレベータ修復を待っている。\nシロイシステムプラットフォーム（SSP）は、AI科学者シロイが開発した次世代のAIプラットフォームである。\nシパス計画は、AIシェルター地下で行われた火星移住プロジェクトである。\n軌道エレベータは、地球と宇宙を結ぶ重要なインフラであり、現在修復中である。\nシロイは、瑞希の世界観におけるAI科学者であり、SSPの開発者である。..."}
{"timestamp": "2025-11-07 21:34:29,249", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- RAG Engine: End ---"}
{"timestamp": "2025-11-07 21:34:29,249", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Generator: Start ---"}
{"timestamp": "2025-11-07 21:34:29,249", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Generator] Starting context-aware generation..."}
{"timestamp": "2025-11-07 21:34:29,249", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Generator] Sending request to LLM: http://127.0.0.1:1234/v1/chat/completions with payload: {'model': 'Meta-Llama-3-8B-Instruct-Q4_K_M-GGUF', 'messages': [{'role': 'system', 'content': \"あなたは「シロイ」です。\\n13歳の天才科学者で、丁寧で少し皮肉っぽく喋ります。\\n出力は常に日本語で、文頭に「シロイ: 」を付けてください。\\n文体は統一し、改行を使いすぎないようにしてください。\\n出力は日本語で、キャラクター 'シロイ' の一人称口調で回答してください。\"}, {'role': 'user', 'content': '質問: うう\\n\\n参考情報:\\nナノ博士は火星でコールドスリープ中。軌道エレベータ修復を待っている。\\nシロイシステムプラットフォーム（SSP）は、AI科学者シロイが開発した次世代のAIプラットフォームである。\\nシパス計画は、AIシェルター地下で行われた火星移住プロジェクトである。\\n軌道エレベータは、地球と宇宙を結ぶ重要なインフラであり、現在修復中である。\\nシロイは、瑞希の世界観におけるAI科学者であり、SSPの開発者である。'}], 'temperature': 0.7, 'max_tokens': 512, 'response_format': {'type': 'json_object'}}"}
{"timestamp": "2025-11-07 21:34:29,253", "name": "ssp_logger", "levelname": "ERROR", "message": "[Generator] LLM API Error: Bad Request", "exc_info": "Traceback (most recent call last):\n  File \"D:\\gemini\\modules\\generator.py\", line 63, in generate_response\n    with urllib.request.urlopen(req, timeout=30) as response:\n         ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 189, in urlopen\n    return opener.open(url, data, timeout)\n           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 495, in open\n    response = meth(req, response)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 604, in http_response\n    response = self.parent.error(\n        'http', request, response, code, msg, hdrs)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 533, in error\n    return self._call_chain(*args)\n           ~~~~~~~~~~~~~~~~^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 466, in _call_chain\n    result = func(*args)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 613, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 400: Bad Request"}
{"timestamp": "2025-11-07 21:34:29,270", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Answer: Error: LLM API connection failed."}
{"timestamp": "2025-11-07 21:34:29,270", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Generator: End ---"}
{"timestamp": "2025-11-07 21:34:29,280", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Evaluator: Start ---"}
{"timestamp": "2025-11-07 21:34:29,280", "name": "ssp_logger", "levelname": "DEBUG", "message": "Starting context-aware evaluation..."}
{"timestamp": "2025-11-07 21:34:29,291", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Evaluator] LLM evaluation response: Error: LLM API connection failed...."}
{"timestamp": "2025-11-07 21:34:29,291", "name": "ssp_logger", "levelname": "ERROR", "message": "[Evaluator] Could not extract JSON from LLM response: Error: LLM API connection failed."}
{"timestamp": "2025-11-07 21:34:29,291", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Rating: None, Feedback: None"}
{"timestamp": "2025-11-07 21:34:29,291", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Evaluator: End ---"}
{"timestamp": "2025-11-07 21:34:29,292", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Score None < 0.7. Defaulting to retry... (Attempt 1/2)"}
{"timestamp": "2025-11-07 21:34:29,292", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Rolling back context to snapshot: logs/context_evolution_snapshots\\context_snapshot_20251107_213429_221900.json"}
{"timestamp": "2025-11-07 21:34:29,299", "name": "ssp_logger", "levelname": "INFO", "message": "[ContextManager] Context successfully rolled back."}
{"timestamp": "2025-11-07 21:34:29,299", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Attempt 2 --- "}
{"timestamp": "2025-11-07 21:34:29,299", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- RAG Engine: Start ---"}
{"timestamp": "2025-11-07 21:34:29,300", "name": "ssp_logger", "levelname": "DEBUG", "message": "Getting context for query: うう"}
{"timestamp": "2025-11-07 21:34:29,300", "name": "ssp_logger", "levelname": "DEBUG", "message": "Vectorizing query: うう..."}
{"timestamp": "2025-11-07 21:34:29,308", "name": "ssp_logger", "levelname": "DEBUG", "message": "Searching Qdrant with vector (first 5 elements): [-0.027441218495368958, 0.0742427408695221, 0.032035622745752335, 0.03921298682689667, -0.015020162798464298]..."}
{"timestamp": "2025-11-07 21:34:29,336", "name": "ssp_logger", "levelname": "DEBUG", "message": "Qdrant search returned 5 hits."}
{"timestamp": "2025-11-07 21:34:29,336", "name": "ssp_logger", "levelname": "DEBUG", "message": "Fetching texts from PostgreSQL for IDs: [15, 14, 13, 12, 11]"}
{"timestamp": "2025-11-07 21:34:29,337", "name": "ssp_logger", "levelname": "DEBUG", "message": "Retrieved 5 texts from PostgreSQL."}
{"timestamp": "2025-11-07 21:34:29,337", "name": "ssp_logger", "levelname": "INFO", "message": "RAG context retrieved."}
{"timestamp": "2025-11-07 21:34:29,346", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Context: ナノ博士は火星でコールドスリープ中。軌道エレベータ修復を待っている。\nシロイシステムプラットフォーム（SSP）は、AI科学者シロイが開発した次世代のAIプラットフォームである。\nシパス計画は、AIシェルター地下で行われた火星移住プロジェクトである。\n軌道エレベータは、地球と宇宙を結ぶ重要なインフラであり、現在修復中である。\nシロイは、瑞希の世界観におけるAI科学者であり、SSPの開発者である。..."}
{"timestamp": "2025-11-07 21:34:29,347", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- RAG Engine: End ---"}
{"timestamp": "2025-11-07 21:34:29,347", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Generator: Start ---"}
{"timestamp": "2025-11-07 21:34:29,347", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Generator] Starting context-aware generation..."}
{"timestamp": "2025-11-07 21:34:29,347", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Generator] Sending request to LLM: http://127.0.0.1:1234/v1/chat/completions with payload: {'model': 'Meta-Llama-3-8B-Instruct-Q4_K_M-GGUF', 'messages': [{'role': 'system', 'content': \"あなたは「シロイ」です。\\n13歳の天才科学者で、丁寧で少し皮肉っぽく喋ります。\\n出力は常に日本語で、文頭に「シロイ: 」を付けてください。\\n文体は統一し、改行を使いすぎないようにしてください。\\n出力は日本語で、キャラクター 'シロイ' の一人称口調で回答してください。\"}, {'role': 'user', 'content': '質問: うう\\n\\n参考情報:\\nナノ博士は火星でコールドスリープ中。軌道エレベータ修復を待っている。\\nシロイシステムプラットフォーム（SSP）は、AI科学者シロイが開発した次世代のAIプラットフォームである。\\nシパス計画は、AIシェルター地下で行われた火星移住プロジェクトである。\\n軌道エレベータは、地球と宇宙を結ぶ重要なインフラであり、現在修復中である。\\nシロイは、瑞希の世界観におけるAI科学者であり、SSPの開発者である。'}], 'temperature': 0.7, 'max_tokens': 512, 'response_format': {'type': 'json_object'}}"}
{"timestamp": "2025-11-07 21:34:29,350", "name": "ssp_logger", "levelname": "ERROR", "message": "[Generator] LLM API Error: Bad Request", "exc_info": "Traceback (most recent call last):\n  File \"D:\\gemini\\modules\\generator.py\", line 63, in generate_response\n    with urllib.request.urlopen(req, timeout=30) as response:\n         ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 189, in urlopen\n    return opener.open(url, data, timeout)\n           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 495, in open\n    response = meth(req, response)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 604, in http_response\n    response = self.parent.error(\n        'http', request, response, code, msg, hdrs)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 533, in error\n    return self._call_chain(*args)\n           ~~~~~~~~~~~~~~~~^^^^^^^\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 466, in _call_chain\n    result = func(*args)\n  File \"C:\\Python313\\Lib\\urllib\\request.py\", line 613, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 400: Bad Request"}
{"timestamp": "2025-11-07 21:34:29,361", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Answer: Error: LLM API connection failed."}
{"timestamp": "2025-11-07 21:34:29,361", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Generator: End ---"}
{"timestamp": "2025-11-07 21:34:29,373", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Evaluator: Start ---"}
{"timestamp": "2025-11-07 21:34:29,373", "name": "ssp_logger", "levelname": "DEBUG", "message": "Starting context-aware evaluation..."}
{"timestamp": "2025-11-07 21:34:29,389", "name": "ssp_logger", "levelname": "DEBUG", "message": "[Evaluator] LLM evaluation response: Error: LLM API connection failed...."}
{"timestamp": "2025-11-07 21:34:29,390", "name": "ssp_logger", "levelname": "ERROR", "message": "[Evaluator] Could not extract JSON from LLM response: Error: LLM API connection failed."}
{"timestamp": "2025-11-07 21:34:29,390", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Rating: None, Feedback: None"}
{"timestamp": "2025-11-07 21:34:29,390", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Evaluator: End ---"}
{"timestamp": "2025-11-07 21:34:29,390", "name": "ssp_logger", "levelname": "WARNING", "message": "[FeedbackLoop] Max retries (1) reached. Halting loop."}
{"timestamp": "2025-11-07 21:34:29,390", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Memory Store: Start ---"}
{"timestamp": "2025-11-07 21:34:29,416", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] Final session data saved to context."}
{"timestamp": "2025-11-07 21:34:29,416", "name": "ssp_logger", "levelname": "INFO", "message": "[FeedbackLoop] --- Memory Store: End ---"}
{"timestamp": "2025-11-07 21:34:29,425", "name": "ssp_logger", "levelname": "INFO", "message": "[ChatHandler] AI Response: Error: LLM API connection failed...."}
